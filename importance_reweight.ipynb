{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of a known noise transition matrix T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.46\n",
      "MSE of the model: 0.54\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(0)\n",
    "X = np.random.randn(1000, 10)\n",
    "y = np.random.randint(0, 2, size=1000)  # Binary classification\n",
    "\n",
    "# Introduce noise\n",
    "noise_rate = 0.2\n",
    "y_noisy = y.copy()\n",
    "n_noisy = int(noise_rate * y.shape[0])\n",
    "noise_indices = np.random.choice(y.shape[0], n_noisy, replace=False)\n",
    "y_noisy[noise_indices] = 1 - y_noisy[noise_indices]  # Flip the labels\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "_, _, y_train_noisy, _ = train_test_split(X, y_noisy, test_size=0.2, random_state=42)\n",
    "\n",
    "# Estimate noise transition matrix T\n",
    "T = np.array([[0.8, 0.2], [0.2, 0.8]])  # Example of a known noise transition matrix\n",
    "\n",
    "# Compute importance weights\n",
    "def compute_importance_weights(y_true, y_noisy, T):\n",
    "    weights = np.zeros_like(y_noisy, dtype=float)\n",
    "    for i in range(len(y_noisy)):\n",
    "        weights[i] = T[y_true[i], y_noisy[i]] / T[y_noisy[i], y_noisy[i]]\n",
    "    return weights\n",
    "\n",
    "weights = compute_importance_weights(y_train, y_train_noisy, T)\n",
    "\n",
    "# Train a classifier with weighted samples\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train_noisy, sample_weight=weights)\n",
    "\n",
    "# Evaluate the classifier\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy on test set:\", accuracy)\n",
    "print(\"MSE of the model:\", mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate T using KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with Importance Reweighting Accuracy on test set: 0.48\n",
      "Logistic Regression Accuracy on clean test set: 0.48\n",
      "SVM Accuracy on clean test set: 0.545\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(0)\n",
    "X = np.random.randn(1000, 10)\n",
    "y = np.random.randint(0, 2, size=1000)\n",
    "\n",
    "# Introduce noise\n",
    "noise_rate = 0.2\n",
    "y_noisy = y.copy()\n",
    "n_noisy = int(noise_rate * y.shape[0])\n",
    "noise_indices = np.random.choice(y.shape[0], n_noisy, replace=False)\n",
    "y_noisy[noise_indices] = 1 - y_noisy[noise_indices]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "_, _, y_train_noisy, _ = train_test_split(X, y_noisy, test_size=0.2, random_state=42)\n",
    "\n",
    "# Kernel Density Estimation (KDE)\n",
    "def estimate_noise_transition_matrix(X, y_noisy, noise_rate):\n",
    "    kde = KernelDensity(kernel='gaussian', bandwidth=0.5).fit(X)\n",
    "    log_density = kde.score_samples(X) # compute log-density of the data points\n",
    "    density = np.exp(log_density)\n",
    "    \n",
    "    # Estimate transition probabilities\n",
    "    p_y_given_x = np.mean(density[y_noisy == 1]) / np.mean(density)\n",
    "    p_not_y_given_x = 1 - p_y_given_x\n",
    "    \n",
    "    # Transition matrix (for binary classification)\n",
    "    T = np.array([[1 - p_not_y_given_x, p_not_y_given_x], \n",
    "                  [p_y_given_x, 1 - p_y_given_x]])\n",
    "    return T\n",
    "\n",
    "T = estimate_noise_transition_matrix(X_train, y_train_noisy, noise_rate)\n",
    "\n",
    "# Compute importance weights\n",
    "def compute_importance_weights(y_true, y_noisy, T):\n",
    "    weights = np.zeros_like(y_noisy, dtype=float)\n",
    "    for i in range(len(y_noisy)):\n",
    "        true_class = y_true[i]\n",
    "        noisy_class = y_noisy[i]\n",
    "        weights[i] = T[true_class, noisy_class] / T[noisy_class, noisy_class]\n",
    "    return weights\n",
    "\n",
    "weights = compute_importance_weights(y_train, y_train_noisy, T)\n",
    "\n",
    "# Train a logistic regression classifier with weighted samples\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train_noisy, sample_weight=weights)\n",
    "# Evaluate the classifier\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Logistic Regression with Importance Reweighting Accuracy on test set:\", accuracy)\n",
    "\n",
    "# Train Logistic Regression on noisy data\n",
    "clf_logistic = LogisticRegression()\n",
    "clf_logistic.fit(X_train, y_train_noisy)\n",
    "# Evaluate the classifiers\n",
    "y_pred_logistic = clf_logistic.predict(X_test)\n",
    "accuracy_logistic = accuracy_score(y_test, y_pred_logistic)\n",
    "print(\"Logistic Regression Accuracy on clean test set:\", accuracy_logistic)\n",
    "\n",
    "# Train SVM on noisy data\n",
    "clf_svm = SVC()\n",
    "clf_svm.fit(X_train, y_train_noisy)\n",
    "# Evaluate the classifiers\n",
    "y_pred_svm = clf_svm.predict(X_test)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"SVM Accuracy on clean test set:\", accuracy_svm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of KDE and asymmetric noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with Importance Reweighting Accuracy on test set: 0.51\n",
      "Logistic Regression Accuracy on clean test set with asymmetric noise: 0.51\n",
      "SVM Accuracy on clean test set with asymmetric noise: 0.51\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(0)\n",
    "X = np.random.randn(1000, 10)\n",
    "y = np.random.randint(0, 2, size=1000)  # Binary classification\n",
    "\n",
    "# Introduce asymmetric noise\n",
    "asym_noise_rate_0_to_1 = 0.1  # Noise rate for class 0 flipped to class 1\n",
    "asym_noise_rate_1_to_0 = 0.3  # Noise rate for class 1 flipped to class 0\n",
    "y_noisy = y.copy()\n",
    "\n",
    "# Flip labels from 0 to 1 with probability asym_noise_rate_0_to_1\n",
    "indices_0_to_1 = np.where(y == 0)[0]\n",
    "flip_indices_0_to_1 = np.random.choice(indices_0_to_1, int(asym_noise_rate_0_to_1 * len(indices_0_to_1)), replace=False)\n",
    "y_noisy[flip_indices_0_to_1] = 1\n",
    "\n",
    "# Flip labels from 1 to 0 with probability asym_noise_rate_1_to_0\n",
    "indices_1_to_0 = np.where(y == 1)[0]\n",
    "flip_indices_1_to_0 = np.random.choice(indices_1_to_0, int(asym_noise_rate_1_to_0 * len(indices_1_to_0)), replace=False)\n",
    "y_noisy[flip_indices_1_to_0] = 0\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "_, _, y_train_noisy, _ = train_test_split(X, y_noisy, test_size=0.2, random_state=42)\n",
    "\n",
    "# Kernel Density Estimation (KDE)\n",
    "def estimate_noise_transition_matrix(X, y_noisy, noise_rate):\n",
    "    kde = KernelDensity(kernel='gaussian', bandwidth=0.5).fit(X)\n",
    "    log_density = kde.score_samples(X) # compute log-density of the data points\n",
    "    density = np.exp(log_density)\n",
    "    \n",
    "    # Estimate transition probabilities\n",
    "    p_y_given_x = np.mean(density[y_noisy == 1]) / np.mean(density)\n",
    "    p_not_y_given_x = 1 - p_y_given_x\n",
    "    \n",
    "    # Transition matrix (for binary classification)\n",
    "    T = np.array([[1 - p_not_y_given_x, p_not_y_given_x], \n",
    "                  [p_y_given_x, 1 - p_y_given_x]])\n",
    "    return T\n",
    "\n",
    "T = estimate_noise_transition_matrix(X_train, y_train_noisy, noise_rate)\n",
    "\n",
    "# Compute importance weights\n",
    "def compute_importance_weights(y_true, y_noisy, T):\n",
    "    weights = np.zeros_like(y_noisy, dtype=float)\n",
    "    for i in range(len(y_noisy)):\n",
    "        true_class = y_true[i]\n",
    "        noisy_class = y_noisy[i]\n",
    "        weights[i] = T[true_class, noisy_class] / T[noisy_class, noisy_class]\n",
    "    return weights\n",
    "\n",
    "weights = compute_importance_weights(y_train, y_train_noisy, T)\n",
    "\n",
    "# Train a logistic regression classifier with weighted samples\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train_noisy, sample_weight=weights)\n",
    "# Evaluate the classifier\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Logistic Regression with Importance Reweighting Accuracy on test set:\", accuracy)\n",
    "\n",
    "# Train Logistic Regression on noisy data\n",
    "clf_logistic = LogisticRegression()\n",
    "clf_logistic.fit(X_train, y_train_noisy)\n",
    "# Evaluate the classifiers\n",
    "y_pred_logistic = clf_logistic.predict(X_test)\n",
    "accuracy_logistic = accuracy_score(y_test, y_pred_logistic)\n",
    "print(\"Logistic Regression Accuracy on clean test set with asymmetric noise:\", accuracy_logistic)\n",
    "\n",
    "# Train SVM on noisy data\n",
    "clf_svm = SVC()\n",
    "clf_svm.fit(X_train, y_train_noisy)\n",
    "y_pred_svm = clf_svm.predict(X_test)\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"SVM Accuracy on clean test set with asymmetric noise:\", accuracy_svm)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
